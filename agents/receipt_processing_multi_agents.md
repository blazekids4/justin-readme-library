# Receipt Processing Scripts - Comprehensive Guide

## 📋 Table of Contents

- [Overview](#overview)
- [Important Disclaimers](#important-disclaimers)
- [Summary](#summary)
- [Value Proposition](#value-proposition)
- [Architecture & Approach](#architecture--approach)
- [Scripts Comparison](#scripts-comparison)
- [How Each Script Works](#how-each-script-works)
- [When to Use Each Approach](#when-to-use-each-approach)
- [Getting Started](#getting-started)
- [Performance Characteristics](#performance-characteristics)
- [Best Practices](#best-practices)
- [Troubleshooting](#troubleshooting)

---

## 🎯 Overview

This directory contains multiple approaches to receipt and document processing, ranging from single-service implementations to sophisticated multi-agent workflows. Each approach has different strengths, use cases, and performance characteristics.

### Available Solutions

1. **Mistral Document AI** - Fast OCR for clear images
2. **Azure Document Intelligence** - Structured receipt data extraction
3. **Azure OpenAI Vision** - AI-powered image analysis with GPT-4 Vision
4. **Azure Content Understanding** - Preview service for comprehensive document analysis
5. **Single-Agent Workflow** - Quality-based intelligent routing
6. **Multi-Agent Workflow** - Parallel processing with result aggregation

---

## ⚠️ Important Disclaimers

**Performance and Cost Estimates**: All performance characteristics, latency estimates, accuracy comparisons, and cost figures mentioned in this document are approximations based on typical service behaviors and should be treated as general guidance only. Actual performance will vary significantly based on:

- Your specific data and document characteristics
- Network conditions and geographic location  
- Service load and current API performance
- Your specific configuration and implementation
- Current pricing (which changes regularly)

**Validation Required**: Before making architectural decisions or capacity planning, you should:

- Conduct your own performance testing with your actual data
- Verify current pricing directly with service providers
- Test accuracy with your specific document types and quality
- Validate throughput under your expected load conditions

**Service Dependencies**: This solution depends on third-party services (Azure, Mistral) whose performance, pricing, and availability may change. Always have contingency plans and monitor service status.

---

## 📊 Summary

### Quick Comparison Matrix

| Approach | Speed | Accuracy | Best For | Cost | Complexity |
|----------|-------|----------|----------|------|------------|
| **Mistral** | ⚡ Very Fast | ⭐⭐⭐ Good | Clear images, bulk processing | 💰 Low | 🔧 Simple |
| **Document Intelligence** | ⚡ Fast | ⭐⭐⭐⭐ Excellent | Structured data, receipts | 💰💰 Medium | 🔧 Simple |
| **Azure OpenAI Vision** | 🐌 Slower | ⭐⭐⭐⭐⭐ Excellent | Blurry/complex images, reasoning | 💰💰💰 High | 🔧 Simple |
| **Content Understanding** | ⚡ Fast | ⭐⭐⭐⭐ Very Good | Multi-modal documents | 💰💰 Medium | 🔧🔧 Moderate |
| **Single-Agent Workflow** | ⚡ Fast | ⭐⭐⭐⭐ Very Good | Mixed quality documents | 💰💰 Medium | 🔧🔧🔧 Complex |
| **Multi-Agent Workflow** | 🐌 Slowest | ⭐⭐⭐⭐⭐ Best | Critical accuracy needs | 💰💰💰 High | 🔧🔧🔧 Complex |

---

## 💎 Value Proposition

### Business Value

**Cost Optimization Through Intelligent Routing**
- Route clear images to fast, low-cost services (Mistral)
- Use expensive, high-accuracy services (Azure OpenAI) only when needed
- Reduce processing costs compared to always using premium services

**Accuracy When It Matters**
- Multi-agent aggregation provides improved accuracy on difficult documents
- Automatic quality assessment ensures optimal service selection
- Confidence scoring helps identify documents needing human review

**Scalability & Throughput**
- Supports batch processing for high-volume scenarios
- Parallel agent execution reduces wall-clock time
- Asynchronous workflows prevent blocking operations

### Technical Value

**Modular Architecture**
- Each script can be used independently or combined
- Shared utilities reduce code duplication
- Easy to add new processing agents

**Production-Ready Features**
- Comprehensive error handling and retry logic
- Detailed logging and telemetry
- Performance metrics and monitoring
- Run-specific output directories for traceability

**Flexible Deployment Options**
- Run locally for development and testing
- Deploy as Azure Functions for serverless execution
- Container-ready for Kubernetes deployment
- Agent framework supports distributed execution

---

## 🏗️ Architecture & Approach

### Processing Pipeline Overview

```
┌─────────────────────────────────────────────────────────────┐
│                    Input: Receipt Images                     │
│                 (Azure Blob Storage)                         │
└───────────────────────────┬─────────────────────────────────┘
                            │
                ┌───────────▼──────────┐
                │  Quality Assessment  │
                │  (AI-powered)        │
                └───┬─────────┬────────┘
                    │         │
          ┌─────────┘         └──────────┐
          │                              │
    ┌─────▼─────┐              ┌────────▼────────┐
    │   Clear   │              │   Blurry or     │
    │  Quality  │              │   Uncertain     │
    └─────┬─────┘              └────────┬────────┘
          │                              │
          │                    ┌─────────┴─────────┐
    ┌─────▼──────┐            │                   │
    │  Mistral   │      ┌─────▼─────┐     ┌──────▼────────┐
    │ Document   │      │ Document  │     │ Azure OpenAI  │
    │    AI      │      │Intelligence│    │    Vision     │
    └─────┬──────┘      └─────┬─────┘     └──────┬────────┘
          │                   │                   │
          │                   └──────┬────────────┘
          │                          │
          │                   ┌──────▼────────┐
          │                   │  Aggregation  │
          │                   │   & Voting    │
          │                   └──────┬────────┘
          │                          │
          └──────────────┬───────────┘
                         │
                  ┌──────▼───────┐
                  │ Final Result │
                  │  + Metadata  │
                  └──────────────┘
```

### Three-Tiered Processing Strategy

**Tier 1: Fast Processing** (Mistral)
- Use for: Clear images, bulk processing
- Characteristics: Fastest processing, lowest cost

**Tier 2: Structured Extraction** (Document Intelligence)
- Use for: Structured data needs, moderate quality
- Characteristics: Good balance of speed and accuracy

**Tier 3: Advanced Analysis** (Azure OpenAI Vision)
- Use for: Blurry images, complex reasoning
- Characteristics: Highest accuracy, premium cost

---

## 🔍 Scripts Comparison

### 1. Individual Service Scripts

#### `mistral/images_ocr.py`
**Purpose**: Fast OCR processing using Mistral Document AI

**Key Features**:
- Processes PNG, JPG, JPEG images
- Batch processing from Azure Blob Storage
- Run-specific output directories
- Detailed summary reports

**Output Structure**:
```
data/responses/mistral/run_YYYYMMDD_HHMMSS/
├── response_receipt_001_png.json
├── response_receipt_002_png.json
└── ...
```

**When to Use**:
- Clear, high-quality receipt images
- Bulk processing scenarios
- Cost-sensitive applications
- Real-time processing needs

---

#### `doc-intelligence/doc-intel-receipts.py`
**Purpose**: Structured receipt data extraction using Azure Document Intelligence

**Key Features**:
- Pre-built receipt model
- Structured field extraction (merchant, date, total, items)
- Confidence scores per field
- Native receipt understanding

**Output Structure**:
```json
{
  "MerchantName": {"value": "Store Name", "confidence": 0.98},
  "TransactionDate": {"value": "2024-10-20", "confidence": 0.95},
  "Total": {"value": 45.67, "confidence": 0.99},
  "Items": [...]
}
```

**When to Use**:
- Need structured receipt data
- Integration with accounting systems
- High confidence scoring required
- Standard receipt formats

---

#### `aoai/azure_openai_analysis.py`
**Purpose**: Advanced image analysis using GPT-4 Vision

**Key Features**:
- Natural language understanding
- Can handle blurry/low-quality images
- Context-aware reasoning
- Markdown-formatted output

**Output Structure**:
```
data/
├── YYYYMMDDTHHMMSS_receipt_name.json    # Raw API response
└── YYYYMMDDTHHMMSS_receipt_name.md      # Formatted markdown
```

**When to Use**:
- Blurry or damaged receipts
- Need contextual reasoning
- Complex document layouts
- Human-readable output needed

---

#### `content-understanding/content_understanding.py`
**Purpose**: Multi-modal document analysis (Preview)

**Key Features**:
- Combines OCR + layout + understanding
- Async polling architecture
- Comprehensive document analysis
- Public URL-based processing

**Output Structure**:
```json
{
  "status": "Succeeded",
  "result": {
    "markdown": "Full document text...",
    "fields": {...},
    "layout": {...}
  }
}
```

**When to Use**:
- Complex multi-page documents
- Need both structure and content
- Experimenting with new capabilities
- Public-facing documents

---

### 2. Workflow Scripts

#### `agents/receipt_analysis_workflow.py`
**Purpose**: Intelligent single-agent routing based on image quality

**Architecture**:
```
Image → Quality Assessment → Route to Best Agent → Result
```

**Key Features**:
- AI-powered quality assessment
- Intelligent routing logic
- Single agent per receipt (cost-effective)
- Detailed workflow logging

**Decision Logic**:
- **Clear** → Mistral (fast & cheap)
- **Blurry** → Document Intelligence (robust)
- **Uncertain** → All three agents + aggregation

**When to Use**:
- Mixed quality document batches
- Cost optimization important
- Standard accuracy requirements
- Production deployments

---

#### `agents/receipt_analysis_all_agents.py`
**Purpose**: Maximum accuracy through multi-agent processing

**Architecture**:
```
                    → Mistral
Image → All Agents  → Document Intelligence  → Aggregation → Best Result
                    → Azure OpenAI Vision
```

**Key Features**:
- Parallel processing of all agents
- Majority voting for field values
- Confidence-weighted aggregation
- Comprehensive result metadata

**Aggregation Strategy**:
- Uses highest confidence value for each field
- Cross-validates across all responses
- Identifies discrepancies
- Provides audit trail

**When to Use**:
- Critical accuracy requirements
- Financial or legal documents
- Audit trails needed
- Validation datasets

---

### 3. Utility Scripts

#### `mistral/load-tests/mistral_load_test.py`
**Purpose**: Performance testing and benchmarking

**Key Features**:
- Configurable load patterns
- Detailed latency metrics (p50, p90, p95, p99)
- CSV + JSON output
- OpenTelemetry support

**Metrics Collected**:
- Request latency (ms)
- Success/failure rates
- Token usage
- Cost estimation
- Concurrency handling

**When to Use**:
- Pre-production validation
- Performance baseline establishment
- Capacity planning
- SLA validation

---

## 🎬 How Each Script Works

### Mistral Document AI (`images_ocr.py`)

**Step-by-Step Process**:

1. **Initialization**
   ```python
   load_dotenv()
   api_key = os.environ.get('AZURE_API_KEY')
   run_id = f"run_{timestamp}"
   ```

2. **Blob Enumeration**
   ```python
   blob_names = get_container_blobs()
   # Returns: ['receipts/001.png', 'receipts/002.png', ...]
   ```

3. **Document Processing Loop**
   ```python
   for blob_name in blob_names:
       # Get image as base64
       base64_image = get_blob_base64(blob_name)
       
       # Determine content type
       content_type = resolve_content_type(blob_name)
       
       # Call Mistral API
       status_code, response = process_document(
           base64_image, api_key, content_type
       )
       
       # Save response
       save_response_to_file(response, filename, run_id)
   ```

4. **Summary Generation**
   ```python
   print(f"Total: {len(blob_names)}")
   print(f"Successful: {len(successful_docs)}")
   print(f"Failed: {len(failed_docs)}")
   ```

**API Payload Structure**:
```json
{
  "model": "mistral-document-ai-2505",
  "document": {
    "type": "image_url",
    "image_url": "data:image/jpeg;base64,..."
  },
  "include_image_base64": false
}
```

---

### Document Intelligence (`doc-intel-receipts.py`)

**Step-by-Step Process**:

1. **Client Initialization**
   ```python
   client = DocumentIntelligenceClient(
       endpoint=endpoint,
       credential=AzureKeyCredential(key)
   )
   ```

2. **Document Analysis**
   ```python
   # Download blob as bytes
   blob_data = download_blob_to_memory(container_client, blob_name)
   
   # Analyze with prebuilt-receipt model
   poller = client.begin_analyze_document(
       "prebuilt-receipt",
       blob_data,
       content_type="application/octet-stream"
   )
   
   # Get results
   receipts = poller.result()
   ```

3. **Field Extraction**
   ```python
   for receipt in receipts.documents:
       merchant = receipt.fields.get("MerchantName")
       date = receipt.fields.get("TransactionDate")
       total = receipt.fields.get("Total")
       items = receipt.fields.get("Items")
   ```

4. **Confidence Scoring**
   ```python
   # Each field includes confidence
   print(f"Merchant: {merchant.value} (confidence: {merchant.confidence})")
   ```

**Extracted Fields**:
- MerchantName, MerchantAddress, MerchantPhoneNumber
- TransactionDate, TransactionTime
- Items (Description, Quantity, Price, TotalPrice)
- Subtotal, Tax, Tip, Total

---

### Azure OpenAI Vision (`azure_openai_analysis.py`)

**Step-by-Step Process**:

1. **Client Setup**
   ```python
   client = AzureOpenAI(
       api_version="2024-12-01-preview",
       azure_endpoint=endpoint,
       api_key=api_key
   )
   ```

2. **Vision API Call**
   ```python
   response = client.chat.completions.create(
       model=deployment,
       messages=[{
           "role": "user",
           "content": [
               {"type": "text", "text": prompt},
               {"type": "image_url", "image_url": {
                   "url": f"data:{content_type};base64,{base64_image}",
                   "detail": "high"
               }}
           ]
       }]
   )
   ```

3. **Prompt Engineering**
   ```
   "Carefully analyze the image of a receipt and extract the exact content.
   If parts are blurred or unclear, spend more time on those areas by:
   - Zooming in and enhancing the image
   - Referencing the overall context
   Do not make up content. Return full text in markdown format.
   Use '[unreadable]' for unclear content."
   ```

4. **Result Processing**
   ```python
   result_text = response.choices[0].message.content
   save_response_files(blob_name, content_type, deployment, 
                       response, result_text)
   ```

**Advantages**:
- Understands context and relationships
- Can infer missing information
- Handles poor image quality
- Natural language output

---

### Content Understanding (`content_understanding.py`)

**Step-by-Step Process**:

1. **Submission Phase**
   ```python
   analyze_url = f"{endpoint}/contentunderstanding/analyzers/prebuilt-imageAnalyzer:analyze?api-version={api_version}"
   
   response = requests.post(analyze_url, headers=headers, json={
       "url": image_url  # Must be publicly accessible
   })
   
   request_id = response.json()["id"]
   ```

2. **Polling Phase**
   ```python
   while attempts < max_attempts:
       time.sleep(polling_interval)
       
       result = requests.get(results_url, headers=headers).json()
       status = result["status"]
       
       if status == "Succeeded":
           return result
       elif status in ["Running", "NotStarted"]:
           continue
   ```

3. **Result Extraction**
   ```json
   {
     "status": "Succeeded",
     "result": {
       "contents": [{
         "markdown": "Extracted text...",
         "fields": {...}
       }]
     }
   }
   ```

**Limitations**:
- Requires publicly accessible URLs (not ideal for private data)
- Async polling adds complexity
- Preview service (subject to change)

---

### Single-Agent Workflow (`receipt_analysis_workflow.py`)

**Architecture Components**:

```python
@executor(id="quality_assessment_agent")
async def quality_assessment_agent(request, ctx):
    """AI-powered quality assessment"""
    # Uses GPT-4o to evaluate image quality
    # Returns: ImageQualityAssessment with routing decision
    
@executor(id="document_intelligence_processor")
async def document_intelligence_processor(request, ctx):
    """Process with Document Intelligence"""
    
@executor(id="mistral_processor")
async def mistral_processor(request, ctx):
    """Process with Mistral"""
    
@executor(id="direct_extraction_processor")
async def direct_extraction_processor(request, ctx):
    """Process with Azure OpenAI Vision"""
    
@executor(id="aggregate_results")
async def aggregate_results(result, ctx):
    """Aggregate and save final results"""
```

**Workflow Graph**:
```python
workflow = (
    WorkflowBuilder()
    .set_start_executor(quality_assessment_agent)
    .add_conditional_edges(
        quality_assessment_agent,
        {
            "clear": [to_mistral_request],
            "blurry": [to_document_intelligence_request],
            "uncertain": [to_multi_agent_request]
        }
    )
    .add_edge(to_mistral_request, mistral_processor)
    .add_edge(to_document_intelligence_request, document_intelligence_processor)
    .add_edge(to_multi_agent_request, document_intelligence_processor)
    .add_edge(to_multi_agent_request, mistral_processor)
    .add_edge(to_multi_agent_request, direct_extraction_processor)
    .add_edge(document_intelligence_processor, aggregate_results)
    .add_edge(mistral_processor, aggregate_results)
    .add_edge(direct_extraction_processor, aggregate_results)
    .build()
)
```

**Quality Assessment Logic**:
```python
# AI evaluates these factors:
- Image sharpness and focus
- Text clarity and readability
- Lighting conditions
- Noise and artifacts
- Overall document condition

# Returns decision:
{
  "quality": "clear|blurry|uncertain",
  "confidence_score": 0.0-1.0,
  "reasoning": "..."
}
```

**Routing Decisions**:
- **Clear (confidence > 0.8)**: → Mistral only
- **Blurry (confidence > 0.8)**: → Document Intelligence only
- **Uncertain (confidence < 0.8)**: → All three agents

---

### Multi-Agent Workflow (`receipt_analysis_all_agents.py`)

**Key Differences from Single-Agent**:

1. **No Quality Assessment**
   ```python
   # Skips quality check, goes straight to all agents
   @executor(id="dispatch_to_all_agents")
   async def dispatch_to_all_agents(request, ctx):
       # Send to all three agents simultaneously
       await ctx.send_message(di_request)
       await ctx.send_message(mistral_request)
       await ctx.send_message(direct_request)
   ```

2. **Parallel Execution**
   ```
   Image → Mistral (1-2s)      ┐
       → Doc Intel (2-3s)    ├→ Aggregation → Result
       → Azure OpenAI (3-5s) ┘
   
   Total time: ~5s (not 6-10s sequential)
   ```

3. **Advanced Aggregation**
   ```python
   def aggregate_results(results_list):
       # Collect all agent responses
       mistral_result = results_list[0]
       doc_intel_result = results_list[1]
       openai_result = results_list[2]
       
       # For each field, choose best value
       final_merchant = highest_confidence(
           mistral_result.merchant_name,
           doc_intel_result.merchant_name,
           openai_result.merchant_name
       )
       
       # Validate consistency
       if all_values_match():
           high_confidence = True
       else:
           flag_for_review = True
   ```

4. **Result Metadata**
   ```json
   {
     "merchant_name": "Store ABC",
     "total_amount": 45.67,
     "metadata": {
       "sources_used": ["mistral", "document_intelligence", "azure_openai"],
       "agreement_level": "high",
       "confidence_scores": {
         "mistral": 0.92,
         "document_intelligence": 0.95,
         "azure_openai": 0.98
       },
       "discrepancies": []
     }
   }
   ```

---

### Load Testing (`mistral_load_test.py`)

**Test Configuration**:
```python
def run_load_test(
    iterations=50,           # Number of documents to process
    base_delay=(0.5, 1.5),  # Random delay between requests
    max_retries=3,           # Retry failed requests
    use_real_blobs=False,    # Use real data or synthetic
    csv_path=None            # Custom output path
):
```

**Execution Flow**:

1. **Setup**
   ```python
   # Initialize telemetry
   telemetry_client = init_telemetry(ai_conn_str)
   
   # Prepare test data
   if use_real_blobs:
       blob_names = get_all_blobs_with_prefix()
   else:
       # Use sample base64 PNG
       sample_base64 = "iVBORw0KGg..."
   ```

2. **Request Loop**
   ```python
   for i in range(iterations):
       # Select document
       if use_real_blobs:
           blob_name = random.choice(blob_names)
           base64_image = get_blob_base64(blob_name)
       
       # Make request with retry
       for attempt in range(max_retries):
           status, response, latency = make_request(...)
           if status == 200:
               break
           time.sleep(exponential_backoff(attempt))
       
       # Record metrics
       latencies.append(latency)
       records.append({...})
   ```

3. **Statistics Calculation**
   ```python
   summary = {
       'count': len(latencies),
       'min_ms': min(latencies),
       'max_ms': max(latencies),
       'mean_ms': statistics.mean(latencies),
       'median_ms': statistics.median(latencies),
       'p50_ms': percentile(latencies, 50),
       'p90_ms': percentile(latencies, 90),
       'p95_ms': percentile(latencies, 95),
       'p99_ms': percentile(latencies, 99),
       'stdev_ms': statistics.stdev(latencies)
   }
   ```

4. **Telemetry Export**
   ```python
   # OpenTelemetry (preferred)
   histogram.record(latency_ms)
   
   # Or Application Insights (fallback)
   tc.track_metric('mistral_latency_ms', latency)
   tc.flush()
   ```

**Output Files**:
- `load_test_YYYYMMDD_HHMMSS.csv` - Detailed per-request metrics
- `load_test_summary_YYYYMMDD_HHMMSS.json` - Aggregated statistics

---

## 🎯 When to Use Each Approach

### Decision Tree

```
START: Need to process receipts
│
├─ Single receipt, need immediate result?
│  ├─ Clear image? → images_ocr.py (Mistral)
│  ├─ Blurry/damaged? → azure_openai_analysis.py
│  └─ Need structured data? → doc-intel-receipts.py
│
├─ Batch processing, cost matters?
│  └─ receipt_analysis_workflow.py (smart routing)
│
├─ Maximum accuracy required?
│  └─ receipt_analysis_all_agents.py (all agents)
│
├─ Testing performance/capacity?
│  └─ mistral_load_test.py
│
└─ Exploring new features?
   └─ content_understanding.py
```

### Use Case Scenarios

#### Scenario 1: E-commerce Returns Processing
**Requirements**: High-volume receipt processing with cost optimization

**Solution**: `receipt_analysis_workflow.py`
- Routes clear images to Mistral for speed and cost efficiency
- Routes blurry images to Document Intelligence for better accuracy
- Sends uncertain cases to all agents for maximum accuracy
- **Result**: Balanced approach optimizing both cost and accuracy

#### Scenario 2: Expense Report Automation
**Requirements**: Extract structured data with high accuracy and audit trail

**Solution**: `doc-intel-receipts.py`
- Pre-built receipt model optimized for this use case
- Structured field extraction with confidence scores
- Built-in support for common receipt formats
- **Result**: Structured JSON ready for accounting system integration

#### Scenario 3: Historical Document Digitization
**Requirements**: Process old, faded, or damaged receipts

**Solution**: `azure_openai_analysis.py`
- GPT-4 Vision can handle poor quality images
- Contextual reasoning fills gaps
- Human-readable markdown output
- **Result**: Best possible extraction from difficult source material

#### Scenario 4: Regulatory Compliance Validation
**Requirements**: Maximum accuracy with full audit trail and multi-source verification

**Solution**: `receipt_analysis_all_agents.py`
- All agents process every receipt
- Cross-validation identifies discrepancies
- Comprehensive metadata and confidence scores
- **Result**: Maximum accuracy with complete audit trail

#### Scenario 5: New Service Evaluation
**Requirements**: Benchmark performance before production

**Solution**: `mistral_load_test.py`
- Test with representative dataset
- Measure latency at various loads
- Validate SLA compliance
- **Result**: Data-driven service selection

---

## 🚀 Getting Started

### Prerequisites

```powershell
# Required
- Python 3.8+
- Azure subscription
- Azure Blob Storage account with receipts

# Required Python packages
pip install -r requirements.txt

# Required environment variables
AZURE_STORAGE_ACCOUNT_NAME=your-account
AZURE_STORAGE_CONTAINER_NAME=your-container
AZURE_API_KEY=your-mistral-key  # For Mistral
DOCUMENT_INTELLIGENCE_ENDPOINT=https://...  # For Doc Intel
DOCUMENT_INTELLIGENCE_KEY=your-key
AZURE_OPENAI_ENDPOINT=https://...  # For Azure OpenAI
AZURE_OPENAI_API_KEY=your-key
AZURE_OPENAI_DEPLOYMENT=your-deployment-name
```

### Quick Start Guide

#### 1. Setup Environment

```powershell
# Clone and navigate
cd "name of project"

# Configure environment
cp .env.example .env
# Edit .env with your credentials

# Authenticate to Azure
az login
```

#### 2. Test Individual Services

```powershell
# Test Mistral
cd mistral
python images_ocr.py

# Test Document Intelligence
cd ..\doc-intelligence
python doc-intel-receipts.py

# Test Azure OpenAI
cd ..\aoai
python azure_openai_analysis.py
```

#### 3. Run Workflow

```powershell
cd ..\agents

# Single-agent workflow (recommended for production)
python receipt_analysis_workflow.py

# Multi-agent workflow (maximum accuracy)
python receipt_analysis_all_agents.py
```

#### 4. Run Load Tests

```powershell
cd ..\mistral\load-tests

# Basic load test
python mistral_load_test.py --iterations 50

# Load test with real data
python mistral_load_test.py --iterations 100 --use-real-blobs

# Async load test
python mistral_load_test.py --async --concurrency 10
```

### Output Locations

All scripts organize outputs by run ID:

```
data/
├── responses/
│   ├── mistral/
│   │   └── run_20251029_143022/
│   │       ├── response_receipt_001.json
│   │       └── response_receipt_002.json
│   ├── document-intelligence/
│   │   └── run_20251029_143545/
│   ├── content-understanding/
│   │   └── ...
│   └── all-agents/
│       ├── final_receipt_001.json
│       └── summary_receipt_001.md
└── workflow_runs/
    └── all_agents_20251029_144812/
        ├── workflow_summary.json
        ├── RUN_ANALYSIS_REPORT.md
        ├── receipts/
        ├── intermediary_outputs/
        └── aggregation_context/
```

---

## 📈 Performance Characteristics

### Relative Performance Overview

*Note: Performance characteristics are estimates based on service architectures and should be validated in your specific environment with your data.*

#### Latency Characteristics

| Service | Relative Speed | Notes |
|---------|----------------|-------|
| Mistral | ⚡ Fastest | Optimized for speed, best for clear images |
| Document Intelligence | ⚡ Fast | Good balance of speed and structured extraction |
| Azure OpenAI Vision | 🐌 Slower | More processing time due to advanced reasoning |
| Content Understanding | ⚡ Fast | Async processing, varies by content complexity |
| Single-Agent Workflow | ⚡ Variable | Depends on routing decisions |
| Multi-Agent Workflow | 🐌 Slowest | Processes multiple agents in parallel |

#### Accuracy Characteristics

| Service | Relative Accuracy | Best Use Cases |
|---------|-------------------|----------------|
| Mistral | Good | Clear, high-quality receipt images |
| Document Intelligence | Excellent | Standard receipt formats, structured data |
| Azure OpenAI Vision | Excellent | Blurry images, complex reasoning needed |
| Content Understanding | Very Good | Multi-modal documents |
| Single-Agent Workflow | Very Good | Mixed quality documents with intelligent routing |
| Multi-Agent Workflow | Best | When maximum accuracy is critical |

#### Cost Characteristics

| Approach | Relative Cost | Cost Factors |
|----------|---------------|--------------|
| Mistral only | Low | Simple OCR processing |
| Document Intelligence only | Medium | Structured extraction premium |
| Azure OpenAI only | High | Advanced AI model costs |
| Single-Agent Workflow | Medium | Optimized routing reduces costs |
| Multi-Agent Workflow | High | Multiple service calls per document |

*Actual costs depend on current service pricing, usage patterns, and specific configurations.*

---

## ✨ Best Practices

### 1. Cost Optimization

**Use Tiered Approach**:
```python
# Good: Smart routing
if image_quality == "clear":
    use_mistral()  # Low cost
elif image_quality == "blurry":
    use_document_intelligence()  # Medium cost
else:
    use_all_agents()  # High cost but maximum accuracy

# Bad: Always use most expensive
always_use_openai()  # High cost for every receipt
```

**Batch Processing**:
```python
# Good: Batch requests when possible
results = await asyncio.gather(*[
    process_receipt(receipt) for receipt in batch
])

# Bad: Sequential processing
for receipt in all_receipts:
    result = await process_receipt(receipt)  # Slow!
```

### 2. Error Handling

**Implement Retry Logic**:
```python
@retry(max_attempts=3, backoff=exponential)
async def process_receipt(receipt):
    try:
        result = await api_call(receipt)
        return result
    except RateLimitError:
        # Wait and retry
        raise
    except ServiceError as e:
        # Log and fallback
        logger.error(f"Service error: {e}")
        return await fallback_processor(receipt)
```

**Graceful Degradation**:
```python
async def robust_processing(receipt):
    try:
        return await primary_service(receipt)
    except PrimaryServiceError:
        logger.warning("Primary failed, trying backup")
        try:
            return await backup_service(receipt)
        except BackupServiceError:
            logger.error("All services failed")
            return {"status": "failed", "receipt": receipt}
```

### 3. Monitoring & Observability

**Log Everything Important**:
```python
logger.info(f"Processing {receipt_id}", extra={
    "receipt_id": receipt_id,
    "service": service_name,
    "image_quality": quality_score,
    "file_size": file_size_bytes
})
```

**Track Metrics**:
```python
# Latency
with track_duration("receipt_processing"):
    result = await process_receipt(receipt)

# Success rates
metrics.increment("receipts.processed")
metrics.increment(f"receipts.{result.status}")

# Costs
estimated_cost = calculate_cost(result)
metrics.histogram("receipts.cost", estimated_cost)
```

### 4. Data Quality

**Validate Inputs**:
```python
def validate_receipt_image(image_data):
    # Check file size
    if len(image_data) > MAX_SIZE:
        raise ValueError("Image too large")
    
    # Check format
    if not is_supported_format(image_data):
        raise ValueError("Unsupported format")
    
    # Check readability
    quality_score = assess_quality(image_data)
    if quality_score < MIN_QUALITY:
        logger.warning("Low quality image detected")
```

**Validate Outputs**:
```python
def validate_extracted_data(result):
    # Check required fields
    if not result.merchant_name:
        logger.warning("Missing merchant name")
    
    # Check data types
    if result.total_amount:
        assert isinstance(result.total_amount, float)
    
    # Check business rules
    if result.total_amount < 0:
        raise ValueError("Negative total amount")
```

### 5. Security

**Never Log Sensitive Data**:
```python
# Good
logger.info(f"Processing receipt {receipt_id}")

# Bad
logger.info(f"Processing receipt: {full_receipt_data}")
```

**Secure Credential Management**:
```python
# Good: Environment variables
api_key = os.environ.get("AZURE_API_KEY")

# Better: Azure Key Vault
from azure.keyvault.secrets import SecretClient
api_key = secret_client.get_secret("mistral-api-key").value

# Bad: Hardcoded
api_key = "abc123..."  # Never do this!
```

### 6. Testing

**Unit Tests**:
```python
def test_aggregate_results():
    results = [
        ReceiptResult(merchant="Store A", total=10.0, source="mistral"),
        ReceiptResult(merchant="Store A", total=10.0, source="doc_intel"),
        ReceiptResult(merchant="Store B", total=10.0, source="openai")
    ]
    
    final = aggregate(results)
    assert final.merchant == "Store A"  # Majority vote
    assert final.metadata.agreement_level == "medium"
```

**Integration Tests**:
```python
async def test_workflow_end_to_end():
    # Use test data
    test_receipt = load_test_receipt()
    
    # Run workflow
    result = await run_workflow(test_receipt)
    
    # Verify output
    assert result.status == "success"
    assert result.merchant_name is not None
    assert result.total_amount > 0
```

**Load Tests**:
```python
# Before production deployment
python mistral_load_test.py --iterations 1000 --use-real-blobs

# Verify performance meets requirements
assert p95_latency < max_acceptable_latency
assert success_rate > minimum_success_rate
```

---

## 🔧 Troubleshooting

### Common Issues

#### Issue: "DefaultAzureCredential failed to retrieve a token"

**Cause**: Azure authentication not configured

**Solution**:
```powershell
# Login to Azure CLI
az login

# Set subscription
az account set --subscription "your-subscription-id"

# Verify access
az storage blob list --account-name your-account --container-name your-container
```

#### Issue: "Rate limit exceeded" (429 errors)

**Cause**: Too many requests to API

**Solution**:
```python
# Add rate limiting
import time
from functools import wraps

def rate_limit(calls_per_minute=60):
    min_interval = 60.0 / calls_per_minute
    last_called = [0.0]
    
    def decorator(func):
        @wraps(func)
        def wrapper(*args, **kwargs):
            elapsed = time.time() - last_called[0]
            wait_time = min_interval - elapsed
            if wait_time > 0:
                time.sleep(wait_time)
            result = func(*args, **kwargs)
            last_called[0] = time.time()
            return result
        return wrapper
    return decorator

@rate_limit(calls_per_minute=30)
def process_receipt(receipt):
    # Your processing code
    pass
```

#### Issue: "Invalid base64 string"

**Cause**: Image encoding issue

**Solution**:
```python
import base64

def safe_base64_encode(data):
    try:
        if isinstance(data, str):
            data = data.encode('utf-8')
        encoded = base64.b64encode(data).decode('utf-8')
        
        # Verify it can be decoded
        base64.b64decode(encoded)
        
        return encoded
    except Exception as e:
        logger.error(f"Base64 encoding failed: {e}")
        raise
```

#### Issue: Workflow hangs or times out

**Cause**: Async operation not completing

**Solution**:
```python
# Add timeouts
import asyncio

async def process_with_timeout(receipt, timeout=30):
    try:
        result = await asyncio.wait_for(
            process_receipt(receipt),
            timeout=timeout
        )
        return result
    except asyncio.TimeoutError:
        logger.error(f"Processing timeout for {receipt}")
        return {"status": "timeout", "receipt": receipt}
```

#### Issue: Memory errors with large batches

**Cause**: Loading too many images at once

**Solution**:
```python
# Process in smaller batches
async def process_batch_chunked(receipts, chunk_size=10):
    results = []
    for i in range(0, len(receipts), chunk_size):
        chunk = receipts[i:i + chunk_size]
        chunk_results = await asyncio.gather(*[
            process_receipt(r) for r in chunk
        ])
        results.extend(chunk_results)
        
        # Clear memory between chunks
        import gc
        gc.collect()
    
    return results
```

#### Issue: Inconsistent aggregation results

**Cause**: Different services returning incompatible formats

**Solution**:
```python
def normalize_result(result, source):
    """Normalize results from different sources"""
    normalized = ReceiptResult()
    
    if source == "mistral":
        normalized.merchant = result.get("merchant_name")
        normalized.total = float(result.get("total", 0))
    elif source == "document_intelligence":
        merchant_field = result.fields.get("MerchantName")
        normalized.merchant = merchant_field.value if merchant_field else None
        total_field = result.fields.get("Total")
        normalized.total = float(total_field.value) if total_field else None
    elif source == "azure_openai":
        # Parse markdown output
        normalized.merchant = extract_merchant_from_markdown(result.text)
        normalized.total = extract_total_from_markdown(result.text)
    
    return normalized
```

---

## 📚 Additional Resources

### Documentation Links

- [Azure Document Intelligence](https://learn.microsoft.com/azure/ai-services/document-intelligence/)
- [Mistral Document AI](https://docs.mistral.ai/capabilities/document-ai/)
- [Azure OpenAI Vision](https://learn.microsoft.com/azure/ai-services/openai/how-to/gpt-with-vision)
- [Azure Content Understanding](https://learn.microsoft.com/azure/ai-services/content-understanding/)
- [Agent Framework](https://github.com/microsoft/azure-agent-framework)

### Related Scripts

- `storage_utils.py` - Azure Blob Storage utilities
- `receipt_workflow_utils.py` - Shared workflow utilities
- `run_workflow.py` - Workflow execution helper

### Sample Data

- `data/ground-truth/` - Validation datasets
- `data/inputs/` - Sample receipts for testing

---

## 🤝 Contributing

When adding new processing scripts:

1. Follow the established patterns (run IDs, output structure)
2. Add comprehensive error handling
3. Include logging and metrics
4. Update this README with your approach
5. Add comparison benchmarks

---

## 📄 License

See main repository LICENSE file.

---

**Last Updated**: October 29, 2025
**Version**: 2.1
**Maintainer**: Justin Lyons

**Note**: This document has been updated to remove specific performance benchmarks and cost estimates that were not based on verifiable test data. All performance characteristics should be validated in your environment with your specific data before making architectural decisions.
