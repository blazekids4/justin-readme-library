# Call Center Executive AI Chat Solution

## User Stories

### Primary Users: Senior Leadership & Executives

1. **As a VP of Customer Experience**, I want to ask "What are the top 3 reasons customers mentioned canceling last month?" and get accurate answers in seconds, so I can prioritize retention initiatives.

2. **As a Regional Director**, I want to see a daily dashboard showing competitor mentions by region, so I can respond quickly to competitive threats.

3. **As a Chief Strategy Officer**, I want to query "How has sentiment changed for customers mentioning Promotion X vs Promotion Y?" to evaluate campaign effectiveness.

### Secondary Users: Analysts & Managers

4. **As a Call Center Manager**, I want to receive weekly automated reports on call sentiment trends, so I can identify training opportunities.

5. **As a Business Analyst**, I want to drill down from summary stats into specific call examples, so I can validate insights and find representative samples.

## Business Logic & Requirements

### Data Processing Requirements

- **Volume**: Scale from 400K to millions of calls monthly
- **Latency**: Near real-time processing (calls processed within 1-4 hours of completion)
- **Accuracy**: >95% entity extraction accuracy with human-in-the-loop validation for edge cases
- **Cost**: Balance LLM processing costs with infrastructure efficiency

### Entity Extraction Priorities

1. **Competitors** (normalized names)
2. **Promotions/Offers** (campaign codes, product names)
3. **Cancellation Reasons** (categorized)
4. **Sentiment** (call-level and topic-level)
5. **Product Issues** (categorized complaints)
6. **Agent Performance Indicators** (resolution, empathy markers)

### Data Retention & Aggregation Strategy

- **Raw transcripts**: 90 days hot storage, 2 years cold storage
- **Enriched call records**: 2 years hot storage
- **Daily aggregates**: 3 years
- **Monthly aggregates**: 7 years

## ROI & Business Value

### The Strategic Importance of the Data Prep Pipeline

**This solution's value is NOT just the chat interfaceâ€”it's the comprehensive data enrichment pipeline that transforms raw call transcripts into actionable intelligence.** The upfront investment in entity extraction and structured data creation unlocks compounding returns across the entire organization.

### ROI Drivers: Cost Reduction & Revenue Growth

**1. Call Center Automation & Cost Reduction**

*Current State:* Manual handling of 400K-2M calls/month with average cost of $5-15 per call

*With Enriched Data:*
- **Identify automation opportunities:** Analyze top call reasons to build self-service flows
- **Automate routine inquiries:** Reduce call volume by 15-25% through intelligent IVR/chatbot deflection
- **Improve first-call resolution:** Better training data leads to fewer callbacks

**Conservative ROI:**
- 2M calls/month Ã— $8 average cost = $16M/month operating cost
- 20% automation rate = 400K calls automated
- **Savings: $3.2M/month ($38.4M/year)**
- **Solution cost: $26-33K/month**
- **ROI: 97x-123x first year**

**2. Agent Training & Retention Improvements**

*Current State:* High agent turnover (30-40% annually), costly training programs, inconsistent performance

*With Enriched Data:*
- **Identify training gaps:** Pinpoint exactly where agents struggle (product knowledge, empathy, objection handling)
- **Targeted coaching:** Use actual call examples for personalized training
- **Improve retention:** Better-trained agents are more confident and stay longer

**Conservative ROI:**
- Reduce turnover from 35% to 28% (saving 7% of workforce)
- 1,000 agents Ã— $50K replacement cost Ã— 7% = **$3.5M/year savings**
- Improved performance drives cross-sell/upsell: 2% increase on $100M revenue = **$2M/year additional revenue**

**3. Product & Marketing Intelligence**

*Current State:* Limited visibility into customer pain points, competitor threats, and campaign effectiveness

*With Enriched Data:*
- **Product insights:** Identify top complaints and feature requests to prioritize roadmap
- **Competitive intelligence:** Real-time monitoring of competitor mentions and win/loss reasons
- **Campaign optimization:** Measure promotion effectiveness and customer sentiment

**Conservative ROI:**
- Faster product iteration reduces churn by 2%: **$2-4M/year** (varies by customer lifetime value)
- Marketing spend optimization (eliminate underperforming campaigns): **$1-2M/year savings**
- Competitive response speed improves win rate by 3-5%: **$3-5M/year revenue**

### Total Annual Value Calculation

| Value Driver | Annual Impact | Conservative Estimate |
|--------------|---------------|----------------------|
| Call automation & deflection | $38.4M | $20-30M (accounting for ramp-up) |
| Agent training & retention | $5.5M | $3-5M |
| Product & marketing intelligence | $6-11M | $4-8M |
| **Total Annual Value** | **$49.9M** | **$27-43M** |
| **Solution Cost (Annual)** | **$315-420K** | **$315-420K** |
| **Net Value** | **$49.5M** | **$26.6-42.7M** |
| **ROI** | **~160x** | **~85-135x** |

### Why Organizations Should NOT Balk at Pricing

**The $26-33K/month investment ($315-420K/year) is not an expenseâ€”it's a strategic enabler that pays for itself 85-160x over.**

**Key Point:** The entity extraction pipeline is doing the heavy analytical work that would otherwise require:
- 10-15 full-time analysts manually categorizing calls
- Expensive BI consultants building custom reports
- Months of delay to get insights that inform decisions

**With this solution:**
- âœ… Insights are automated and real-time (1-4 hour latency)
- âœ… Executives get instant answers via natural language
- âœ… Data quality is consistent (>95% accuracy with LLM extraction)
- âœ… Historical trends are preserved and queryable
- âœ… The data asset appreciates over time (more history = better insights)

### The Data Goldmine Compounds Over Time

**Month 1-3:** Foundationâ€”building pipelines, establishing baselines
**Month 4-6:** Quick winsâ€”identifying obvious automation opportunities and training gaps
**Month 7-12:** Optimizationâ€”iterating on products, refining call center operations
**Year 2+:** Strategic advantageâ€”predictive churn modeling, proactive competitive response, AI-driven product roadmapping

**The longer this system runs, the more valuable it becomes.** Two years of enriched call data enables:
- Seasonal trend analysis
- Year-over-year comparisons
- Predictive modeling for churn risk
- Early warning systems for product issues
- Competitive threat detection

### Bottom Line

**Organizations that hesitate on pricing are missing the forest for the trees.** The investment in the data prep pipeline is what unlocks enterprise-wide transformation:

1. **Automate more** â†’ Reduce call center expenses by millions
2. **Train better** â†’ Improve retention and drive cross-sell revenue
3. **Build smarter** â†’ Mine consumer insights to create better products and campaigns

**The question isn't "Can we afford this?"â€”it's "Can we afford NOT to do this while competitors are?"**

## Technical Architecture

### Tech Stack Recommendation

**Unified Data Platform: Microsoft Fabric**

- **Data Engineering**: Fabric Spark (notebooks, pipelines)
- **Orchestration**: Fabric Data Factory pipelines
- **Storage**: OneLake (unified data lake)
- **Data Warehouse**: Fabric Data Warehouse
- **Semantic Layer**: Power BI semantic models (built-in)
- **Natural Language Interface**: Fabric Copilot/Data Agent
- **Monitoring**: Fabric monitoring + Azure Monitor

**Data Ingestion Layer**

- **Message Queue**: Azure Event Hubs (for call transcript streaming)

**AI/ML Processing Layer**

- **LLM Service**: Azure OpenAI Service (GPT-4.1 for entity extraction)
- **Prompt Management**: Microsoft Agent Framework / Azure AI Foundry SDK
- **Vector Storage**: Azure AI Search
- **Model Monitoring**: AI Foundry Observability tools

**Analytics & Interface Layer**

- **Natural Language Interface**: Fabric Data Agent (consumed via AI Foundry Agent Service)
- **Visualization**: Power BI (Direct Lake mode)
- **API Layer**: Azure API Management (for programmatic access, optional)
- **Caching**: Azure Redis Cache (for common queries, optional)

**Monitoring & Governance**

- **Observability**: Azure Monitor, Application Insights
- **Data Governance**: Microsoft Purview (integrated with Fabric)
- **Cost Management**: Azure Cost Management

## Process Flow

### 1. Real-Time Ingestion Pipeline

```
Call Completed â†’ Transcription System â†’ Event Hub â†’ Stream Processing
                                                    â†“
                                            OneLake Bronze Layer
```

### 2. Entity Extraction Pipeline (Batch)

```
Scheduled Job (Hourly/4-hourly)
    â†“
Fabric Spark reads new transcripts from Bronze
    â†“
Partition into micro-batches (1000 calls each)
    â†“
Parallel LLM Processing (GPT-4.1)
    â”œâ”€ Competitor Extraction
    â”œâ”€ Promotion Extraction
    â”œâ”€ Cancellation Reason Extraction
    â”œâ”€ Sentiment Analysis
    â””â”€ Other Entity Extraction
    â†“
Validate & Normalize Entities
    â†“
Write to Silver Layer (Enriched Call Records)
    â†“
Trigger Downstream Aggregations
```

### 3. Aggregation Pipeline

```
Silver Layer: Enriched Call Records
    â†“
Triggered Aggregation Jobs (Fabric Spark)
    â”œâ”€ Daily Rollups (by region, product, competitor)
    â”œâ”€ Weekly Rollups
    â””â”€ Monthly Rollups
    â†“
Gold Layer: Curated Analytics Tables
    â†“
Power BI Semantic Models (Direct Lake)
```

### 4. Query & Analytics Flow

```
User Natural Language Query
    â†“
Fabric Data Agent (Copilot)
    â”œâ”€ Check Cache (Redis, optional)
    â”œâ”€ Semantic Search (Vector via Azure AI Search)
    â””â”€ SQL Generation (NL2SQL)
    â†“
Query Optimizer (routes to appropriate table)
    â”œâ”€ Gold Layer Tables (for summary queries)
    â””â”€ Silver Layer (for detailed queries)
    â†“
Results + Citation (specific call IDs)
    â†“
User Interface
```

## Detailed Architecture Diagram

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                         DATA SOURCES                                 â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”              â”‚
â”‚  â”‚ Call Center  â”‚  â”‚ Transcriptionâ”‚  â”‚   CRM/Other  â”‚              â”‚
â”‚  â”‚   Systems    â”‚â†’ â”‚   Service    â”‚â†’ â”‚   Metadata   â”‚              â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜              â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                             â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                    INGESTION LAYER                                   â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”            â”‚
â”‚  â”‚           Azure Event Hubs                           â”‚            â”‚
â”‚  â”‚  (Real-time transcript streaming)                    â”‚            â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜            â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                          â†“
â•”â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•—
â•‘                     MICROSOFT FABRIC WORKSPACE                       â•‘
â•‘                                                                      â•‘
â•‘  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â” â•‘
â•‘  â”‚                    ONELAKE (Unified Storage)                   â”‚ â•‘
â•‘  â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”‚ â•‘
â•‘  â”‚  â”‚  Lakehouse: CallCenter_Bronze                           â”‚  â”‚ â•‘
â•‘  â”‚  â”‚  - Raw transcripts (JSON/Parquet)                       â”‚  â”‚ â•‘
â•‘  â”‚  â”‚  - Partitioned by date                                  â”‚  â”‚ â•‘
â•‘  â”‚  â”‚  - 90-day hot, 2-year archive                           â”‚  â”‚ â•‘
â•‘  â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â”‚ â•‘
â•‘  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â•‘
â•‘                             â†“                                       â•‘
â•‘  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â” â•‘
â•‘  â”‚              DATA FACTORY PIPELINES                            â”‚ â•‘
â•‘  â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”‚ â•‘
â•‘  â”‚  â”‚  Pipeline 1: Ingest_Transcripts                         â”‚  â”‚ â•‘
â•‘  â”‚  â”‚  - Triggered by Event Hub                               â”‚  â”‚ â•‘
â•‘  â”‚  â”‚  - Writes to Bronze layer                               â”‚  â”‚ â•‘
â•‘  â”‚  â”‚  - Frequency: Real-time/Micro-batch (15 min)            â”‚  â”‚ â•‘
â•‘  â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â”‚ â•‘
â•‘  â”‚                                                                 â”‚ â•‘
â•‘  â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”‚ â•‘
â•‘  â”‚  â”‚  Pipeline 2: Entity_Extraction                          â”‚  â”‚ â•‘
â•‘  â”‚  â”‚  - Scheduled: Every 4 hours                             â”‚  â”‚ â•‘
â•‘  â”‚  â”‚  - Triggers Spark notebook                              â”‚  â”‚ â•‘
â•‘  â”‚  â”‚  - Includes error handling & retry logic                â”‚  â”‚ â•‘
â•‘  â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â”‚ â•‘
â•‘  â”‚                                                                 â”‚ â•‘
â•‘  â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”‚ â•‘
â•‘  â”‚  â”‚  Pipeline 3: Daily_Aggregations                         â”‚  â”‚ â•‘
â•‘  â”‚  â”‚  - Scheduled: Daily at 2 AM                             â”‚  â”‚ â•‘
â•‘  â”‚  â”‚  - Triggers aggregation notebook                        â”‚  â”‚ â•‘
â•‘  â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â”‚ â•‘
â•‘  â”‚                                                                 â”‚ â•‘
â•‘  â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”‚ â•‘
â•‘  â”‚  â”‚  Pipeline 4: Weekly_Monthly_Analytics                   â”‚  â”‚ â•‘
â•‘  â”‚  â”‚  - Scheduled: Weekly (Monday) / Monthly (1st)           â”‚  â”‚ â•‘
â•‘  â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â”‚ â•‘
â•‘  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â•‘
â•‘                             â†“                                       â•‘
â•‘  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â” â•‘
â•‘  â”‚            FABRIC SPARK (Data Engineering)                     â”‚ â•‘
â•‘  â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”‚ â•‘
â•‘  â”‚  â”‚  Notebook: Entity_Extraction_Engine                     â”‚  â”‚ â•‘
â•‘  â”‚  â”‚  - Reads new transcripts from Bronze layer              â”‚  â”‚ â•‘
â•‘  â”‚  â”‚  - Partitions into micro-batches (1000 calls each)      â”‚  â”‚ â•‘
â•‘  â”‚  â”‚  - Calls Azure OpenAI for parallel processing           â”‚  â”‚ â•‘
â•‘  â”‚  â”‚                                                           â”‚  â”‚ â•‘
â•‘  â”‚  â”‚  Entity Extraction Tasks:                                â”‚  â”‚ â•‘
â•‘  â”‚  â”‚    â€¢ Competitor extraction & normalization               â”‚  â”‚ â•‘
â•‘  â”‚  â”‚    â€¢ Promotion/offer identification                      â”‚  â”‚ â•‘
â•‘  â”‚  â”‚    â€¢ Cancellation reason categorization                  â”‚  â”‚ â•‘
â•‘  â”‚  â”‚    â€¢ Sentiment analysis (call & topic level)             â”‚  â”‚ â•‘
â•‘  â”‚  â”‚    â€¢ Product issue categorization                        â”‚  â”‚ â•‘
â•‘  â”‚  â”‚    â€¢ Agent performance indicators                        â”‚  â”‚ â•‘
â•‘  â”‚  â”‚                                                           â”‚  â”‚ â•‘
â•‘  â”‚  â”‚  Validation & Normalization:                             â”‚  â”‚ â•‘
â•‘  â”‚  â”‚    â€¢ Entity deduplication                                â”‚  â”‚ â•‘
â•‘  â”‚  â”‚    â€¢ Confidence scoring                                  â”‚  â”‚ â•‘
â•‘  â”‚  â”‚    â€¢ Reference data lookups                              â”‚  â”‚ â•‘
â•‘  â”‚  â”‚                                                           â”‚  â”‚ â•‘
â•‘  â”‚  â”‚  - Writes enriched data to Silver layer                  â”‚  â”‚ â•‘
â•‘  â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â”‚ â•‘
â•‘  â”‚                                                                 â”‚ â•‘
â•‘  â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”‚ â•‘
â•‘  â”‚  â”‚  Notebook: Aggregation_Engine                           â”‚  â”‚ â•‘
â•‘  â”‚  â”‚  - Reads from Silver layer                               â”‚  â”‚ â•‘
â•‘  â”‚  â”‚  - Generates daily/weekly/monthly rollups                â”‚  â”‚ â•‘
â•‘  â”‚  â”‚  - Anomaly detection                                     â”‚  â”‚ â•‘
â•‘  â”‚  â”‚  - Predictive churn scoring                              â”‚  â”‚ â•‘
â•‘  â”‚  â”‚  - Writes to Gold layer (optimized tables)               â”‚  â”‚ â•‘
â•‘  â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â”‚ â•‘
â•‘  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â•‘
â•‘                             â†“                                       â•‘
â•‘  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â” â•‘
â•‘  â”‚              ONELAKE LAKEHOUSE - SILVER LAYER                  â”‚ â•‘
â•‘  â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”‚ â•‘
â•‘  â”‚  â”‚  ğŸ“Š ENRICHED CALL RECORDS (Primary Table)               â”‚  â”‚ â•‘
â•‘  â”‚  â”‚                                                           â”‚  â”‚ â•‘
â•‘  â”‚  â”‚  Columns:                                                â”‚  â”‚ â•‘
â•‘  â”‚  â”‚    - CallID, Date, Duration, CustomerID                  â”‚  â”‚ â•‘
â•‘  â”‚  â”‚    - Transcript, TranscriptEmbedding (vector)            â”‚  â”‚ â•‘
â•‘  â”‚  â”‚    - Competitor1, Competitor2, Competitor3               â”‚  â”‚ â•‘
â•‘  â”‚  â”‚    - Promotions, CancellationReasons                     â”‚  â”‚ â•‘
â•‘  â”‚  â”‚    - SentimentScore, SentimentLabel                      â”‚  â”‚ â•‘
â•‘  â”‚  â”‚    - ProductIssues, AgentID, Region                      â”‚  â”‚ â•‘
â•‘  â”‚  â”‚                                                           â”‚  â”‚ â•‘
â•‘  â”‚  â”‚  Partitioned by: Date (day)                              â”‚  â”‚ â•‘
â•‘  â”‚  â”‚  Format: Delta Lake (ACID transactions)                  â”‚  â”‚ â•‘
â•‘  â”‚  â”‚  Z-Ordered on: Date, CustomerID, Competitors             â”‚  â”‚ â•‘
â•‘  â”‚  â”‚  Retention: 2 years hot storage                          â”‚  â”‚ â•‘
â•‘  â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â”‚ â•‘
â•‘  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â•‘
â•‘                             â†“                                       â•‘
â•‘  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â” â•‘
â•‘  â”‚              ONELAKE LAKEHOUSE - GOLD LAYER                    â”‚ â•‘
â•‘  â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”‚ â•‘
â•‘  â”‚  â”‚  ğŸ“ˆ AGGREGATED ANALYTICS TABLES                         â”‚  â”‚ â•‘
â•‘  â”‚  â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”‚  â”‚ â•‘
â•‘  â”‚  â”‚  â”‚  â€¢ daily_competitor_stats                         â”‚  â”‚  â”‚ â•‘
â•‘  â”‚  â”‚  â”‚    (Date, Competitor, Region, MentionCount,       â”‚  â”‚  â”‚ â•‘
â•‘  â”‚  â”‚  â”‚     AvgSentiment, TopIssues)                      â”‚  â”‚  â”‚ â•‘
â•‘  â”‚  â”‚  â”‚                                                    â”‚  â”‚  â”‚ â•‘
â•‘  â”‚  â”‚  â”‚  â€¢ daily_promotion_performance                    â”‚  â”‚  â”‚ â•‘
â•‘  â”‚  â”‚  â”‚    (Date, Promotion, MentionCount,                â”‚  â”‚  â”‚ â•‘
â•‘  â”‚  â”‚  â”‚     ConversionRate, AvgSentiment)                 â”‚  â”‚  â”‚ â•‘
â•‘  â”‚  â”‚  â”‚                                                    â”‚  â”‚  â”‚ â•‘
â•‘  â”‚  â”‚  â”‚  â€¢ daily_cancellation_summary                     â”‚  â”‚  â”‚ â•‘
â•‘  â”‚  â”‚  â”‚    (Date, Reason, Count, Region, Product)         â”‚  â”‚  â”‚ â•‘
â•‘  â”‚  â”‚  â”‚                                                    â”‚  â”‚  â”‚ â•‘
â•‘  â”‚  â”‚  â”‚  â€¢ daily_sentiment_trends                         â”‚  â”‚  â”‚ â•‘
â•‘  â”‚  â”‚  â”‚  â€¢ weekly_analytics                               â”‚  â”‚  â”‚ â•‘
â•‘  â”‚  â”‚  â”‚  â€¢ monthly_executive_summary                      â”‚  â”‚  â”‚ â•‘
â•‘  â”‚  â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â”‚  â”‚ â•‘
â•‘  â”‚  â”‚                                                           â”‚  â”‚ â•‘
â•‘  â”‚  â”‚  Format: Delta Lake (optimized, compacted)               â”‚  â”‚ â•‘
â•‘  â”‚  â”‚  Retention: Daily (3 years), Monthly (7 years)           â”‚  â”‚ â•‘
â•‘  â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â”‚ â•‘
â•‘  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â•‘
â•‘                             â†“                                       â•‘
â•‘  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â” â•‘
â•‘  â”‚              FABRIC DATA WAREHOUSE (Optional)                  â”‚ â•‘
â•‘  â”‚  - SQL views over Gold lakehouse tables                        â”‚ â•‘
â•‘  â”‚  - Optimized for BI tool queries                               â”‚ â•‘
â•‘  â”‚  - Row-level security for sensitive data                       â”‚ â•‘
â•‘  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â•‘
â•‘                             â†“                                       â•‘
â•‘  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â” â•‘
â•‘  â”‚                   FABRIC COPILOT / DATA AGENT                  â”‚ â•‘
â•‘  â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”‚ â•‘
â•‘  â”‚  â”‚  Natural Language Query Interface                       â”‚  â”‚ â•‘
â•‘  â”‚  â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”‚  â”‚ â•‘
â•‘  â”‚  â”‚  â”‚  Query Understanding Layer                        â”‚  â”‚  â”‚ â•‘
â•‘  â”‚  â”‚  â”‚  - Intent classification                          â”‚  â”‚  â”‚ â•‘
â•‘  â”‚  â”‚  â”‚  - Entity recognition                             â”‚  â”‚  â”‚ â•‘
â•‘  â”‚  â”‚  â”‚  - Context awareness                              â”‚  â”‚  â”‚ â•‘
â•‘  â”‚  â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â”‚  â”‚ â•‘
â•‘  â”‚  â”‚              â†“                                            â”‚  â”‚ â•‘
â•‘  â”‚  â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”‚  â”‚ â•‘
â•‘  â”‚  â”‚  â”‚  Query Router                                     â”‚  â”‚  â”‚ â•‘
â•‘  â”‚  â”‚  â”‚  IF summary/aggregate query:                      â”‚  â”‚  â”‚ â•‘
â•‘  â”‚  â”‚  â”‚    â†’ Gold layer (fast response)                   â”‚  â”‚  â”‚ â•‘
â•‘  â”‚  â”‚  â”‚  ELIF specific call examples:                     â”‚  â”‚  â”‚ â•‘
â•‘  â”‚  â”‚  â”‚    â†’ Silver layer + filters                       â”‚  â”‚  â”‚ â•‘
â•‘  â”‚  â”‚  â”‚  ELIF semantic similarity:                        â”‚  â”‚  â”‚ â•‘
â•‘  â”‚  â”‚  â”‚    â†’ Vector search (Azure AI Search)              â”‚  â”‚  â”‚ â•‘
â•‘  â”‚  â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â”‚  â”‚ â•‘
â•‘  â”‚  â”‚              â†“                                            â”‚  â”‚ â•‘
â•‘  â”‚  â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”‚  â”‚ â•‘
â•‘  â”‚  â”‚  â”‚  Query Execution                                  â”‚  â”‚  â”‚ â•‘
â•‘  â”‚  â”‚  â”‚  - NL2SQL generation                              â”‚  â”‚  â”‚ â•‘
â•‘  â”‚  â”‚  â”‚  - Query optimization                             â”‚  â”‚  â”‚ â•‘
â•‘  â”‚  â”‚  â”‚  - Result formatting                              â”‚  â”‚  â”‚ â•‘
â•‘  â”‚  â”‚  â”‚  - Source citation (CallIDs)                      â”‚  â”‚  â”‚ â•‘
â•‘  â”‚  â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â”‚  â”‚ â•‘
â•‘  â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â”‚ â•‘
â•‘  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â•‘
â•‘                             â†“                                       â•‘
â•‘  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â” â•‘
â•‘  â”‚                      POWER BI                                  â”‚ â•‘
â•‘  â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”‚ â•‘
â•‘  â”‚  â”‚  Semantic Models (Direct Lake mode)                     â”‚  â”‚ â•‘
â•‘  â”‚  â”‚  - Direct query to Delta tables in lakehouse            â”‚  â”‚ â•‘
â•‘  â”‚  â”‚  - No data import needed (real-time)                    â”‚  â”‚ â•‘
â•‘  â”‚  â”‚  - Automatic refresh                                    â”‚  â”‚ â•‘
â•‘  â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â”‚ â•‘
â•‘  â”‚              â†“                                                  â”‚ â•‘
â•‘  â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”‚ â•‘
â•‘  â”‚  â”‚  Executive Dashboards                                   â”‚  â”‚ â•‘
â•‘  â”‚  â”‚  â€¢ Executive KPI Dashboard (daily refresh)              â”‚  â”‚ â•‘
â•‘  â”‚  â”‚  â€¢ Competitor Intelligence Dashboard                    â”‚  â”‚ â•‘
â•‘  â”‚  â”‚  â€¢ Promotion Performance Dashboard                      â”‚  â”‚ â•‘
â•‘  â”‚  â”‚  â€¢ Sentiment & Churn Risk Dashboard                     â”‚  â”‚ â•‘
â•‘  â”‚  â”‚  â€¢ Daily Operations Dashboard                           â”‚  â”‚ â•‘
â•‘  â”‚  â”‚  â€¢ Drill-through to call details                        â”‚  â”‚ â•‘
â•‘  â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â”‚ â•‘
â•‘  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â•‘
â•‘                                                                      â•‘
â•‘  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â” â•‘
â•‘  â”‚                 FABRIC MONITORING                              â”‚ â•‘
â•‘  â”‚  - Pipeline execution status                                   â”‚ â•‘
â•‘  â”‚  - Spark job performance                                       â”‚ â•‘
â•‘  â”‚  - Capacity utilization (CU consumption)                       â”‚ â•‘
â•‘  â”‚  - Data quality metrics                                        â”‚ â•‘
â•‘  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â•‘
â•šâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
                             â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                    EXTERNAL INTEGRATIONS                             â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”       â”‚
â”‚  â”‚         Azure OpenAI Service                             â”‚       â”‚
â”‚  â”‚  - Entity extraction via API calls from Spark            â”‚       â”‚
â”‚  â”‚  - Batch API for cost optimization                       â”‚       â”‚
â”‚  â”‚  - Token usage monitoring                                â”‚       â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜       â”‚
â”‚                                                                      â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”       â”‚
â”‚  â”‚         Azure AI Search (Vector Database)                â”‚       â”‚
â”‚  â”‚  - Stores transcript embeddings                          â”‚       â”‚
â”‚  â”‚  - Enables semantic search                               â”‚       â”‚
â”‚  â”‚  - Synced from enriched_calls table                      â”‚       â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜       â”‚
â”‚                                                                      â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”       â”‚
â”‚  â”‚         Azure Redis Cache (Optional)                     â”‚       â”‚
â”‚  â”‚  - Caches frequent query results                         â”‚       â”‚
â”‚  â”‚  - Reduces load on Fabric capacity                       â”‚       â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜       â”‚
â”‚                                                                      â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”       â”‚
â”‚  â”‚         Microsoft Purview                                â”‚       â”‚
â”‚  â”‚  - Data lineage (automatic from Fabric)                  â”‚       â”‚
â”‚  â”‚  - PII detection & classification                        â”‚       â”‚
â”‚  â”‚  - Compliance reporting                                  â”‚       â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜       â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                             â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                         END USERS                                    â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”              â”‚
â”‚  â”‚  Executives  â”‚  â”‚   Managers   â”‚  â”‚   Analysts   â”‚              â”‚
â”‚  â”‚  (Copilot +  â”‚  â”‚ (Dashboards) â”‚  â”‚  (Reports +  â”‚              â”‚
â”‚  â”‚  Dashboards) â”‚  â”‚              â”‚  â”‚   Ad-hoc)    â”‚              â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜              â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

## Implementation Recommendations

### Phase 1: Foundation (Months 1-2)

1. **Infrastructure Setup**

   - Provision Fabric workspace (F64 or F128 capacity)
   - Set up lakehouses (Bronze, Silver, Gold)
   - Configure Event Hub integration
   - Establish data governance policies

2. **Pipeline Development**
   - Build ingestion pipeline (Event Hub â†’ Bronze)
   - Create Spark notebook for entity extraction
   - Set up Azure OpenAI connection
   - Develop validation logic

### Phase 2: Scale & Optimize (Months 3-4)

1. **Performance Optimization**

   - Implement batch processing at scale
   - Optimize Spark partitioning
   - Optimize LLM prompts for cost efficiency
   - Add error handling & retry logic
   - Monitor capacity utilization
   - Tune partitioning strategies

2. **Expand Entity Coverage**
   - Add remaining entity types
   - Build entity reference tables
   - Implement confidence scoring

### Phase 3: Analytics & Intelligence (Months 5-6)

1. **Build Aggregation Pipelines**

   - Build daily aggregation notebooks
   - Create Gold layer tables
   - Set up scheduled pipelines
   - Test incremental processing
   - Daily/weekly/monthly rollups
   - Trend analysis
   - Anomaly detection

2. **Create Curated Dashboards**
   - Create semantic models (Direct Lake)
   - Build executive dashboards
   - Set up row-level security
   - Configure automatic refresh
   - Executive dashboards
   - Operational dashboards
   - Self-service analytics

### Phase 4: Refinement & MLOps (Ongoing)

1. **Model Monitoring**

   - Track extraction accuracy
   - A/B test prompt variations
   - Implement human-in-the-loop feedback

2. **Cost Optimization**
   - Monitor LLM token usage
   - Optimize batch sizes
   - Implement tiered storage
   - Optimize Delta table layout (VACUUM, OPTIMIZE)
   - Add Z-ordering on key columns

## Key Design Decisions & Rationale

**Why Batch vs. Real-Time for Entity Extraction?**

- Batch processing (hourly/4-hourly) balances cost and latency
- Allows for micro-batch optimization and retry logic
- Real-time extraction would be 10x more expensive

**Why Pre-Aggregate Data?**

- 80% of executive queries hit the same patterns
- Pre-aggregation reduces query latency from 10-30s to <1s
- Dramatically reduces costs (fewer LLM calls for analysis)
- Enables complex trend analysis without scanning millions of rows

**Why Hybrid Search (NL2SQL + Vector)?**

- SQL for structured queries (counts, filters, aggregations)
- Vector search for semantic similarity ("Find calls similar to this complaint")
- Best of both worlds for enterprise analytics

**Why Fabric Instead of Databricks?**

- **Unified Platform**: Single workspace for all components (Spark, storage, BI, Copilot)
- **Direct Lake Mode**: Power BI queries Delta tables directly with no import/refresh delays
- **OneLake Architecture**: One copy of data shared across all Fabric workloads
- **Native Copilot Integration**: Built into the platform with seamless data model understanding
- **Cost Predictability**: Capacity Units (CU) pricing model easier to forecast than DBU consumption
- **Simpler Governance**: Integrated with Purview for automatic lineage tracking
- **Volume Appropriate**: Fabric Spark handles 2M calls/month efficiently without needing Databricks Photon

**Query Routing Strategy**

```
User Query â†’ Fabric Data Agent
    â†“
Query Classifier
    â”œâ”€ "How many calls mentioned Verizon last week?"
    â”‚   â†’ SQL on daily_competitor_stats (Gold layer - fast)
    â”‚
    â”œâ”€ "Show me examples of angry customers mentioning prices"
    â”‚   â†’ Vector search + sentiment filter on enriched_calls (Silver layer)
    â”‚
    â””â”€ "Compare our promotion performance to Q3"
        â†’ SQL on aggregated tables (Gold layer) + previous quarter comparison
```

## Cost Estimation Framework

### LLM Processing Costs (Azure OpenAI GPT-4.1 Series)

> **Note:** Fabric Data Agent queries (NL2SQL + vector search) are NOT included in these costs - they use a separate quota/budget. These costs are ONLY for the entity extraction pipeline processing.

**Model Selection Strategy:**

- **GPT-4.1:** Complex entity extraction (competitors, promotions, cancellation reasons, product issues)
- **GPT-4.1-mini:** Simpler tasks (sentiment analysis, basic categorization, agent performance indicators)
- **Fabric Data Agent:** Handles all user queries separately (not counted here)

**Pricing Tiers (Per 1M Tokens) - Global Deployment:**

| Model            | Standard Input | Cached Input | Standard Output | Batch Input | Batch Output |
| ---------------- | -------------- | ------------ | --------------- | ----------- | ------------ |
| **GPT-4.1**      | $2.00          | $0.50        | $8.00           | $1.00       | $4.00        |
| **GPT-4.1-mini** | $0.40          | $0.10        | $1.60           | $0.20       | $0.80        |

**Provisioned Throughput Units (PTU):**

- Monthly Reservation: $286/PTU
- Yearly Reservation: $286 Ã— 12 = $3,432/PTU (no discount mentioned, but commitment)

**Per-Call Processing Breakdown:**

Each call requires multiple LLM operations:

**High-Complexity Extraction (GPT-4.1):**

- Transcript: 1,500 tokens
- System prompt + entity reference lists: 800 tokens (cached after first use)
- Output (structured entities): 600 tokens
- Tasks: Competitor extraction, promotion identification, cancellation reasons, product issues

**Low-Complexity Extraction (GPT-4.1-mini):**

- Transcript: 1,500 tokens (reused)
- System prompt: 300 tokens (cached)
- Output: 200 tokens
- Tasks: Sentiment analysis, basic categorization, agent performance scoring

**Option 1: Standard API (No Caching)**

_GPT-4.1 (Complex Extraction):_

- Input: (2,300 tokens Ã— $2.00) / 1M = $0.0046
- Output: (600 tokens Ã— $8.00) / 1M = $0.0048
- Subtotal: $0.0094

_GPT-4.1-mini (Simple Tasks):_

- Input: (1,800 tokens Ã— $0.40) / 1M = $0.00072
- Output: (200 tokens Ã— $1.60) / 1M = $0.00032
- Subtotal: $0.00104

**Per call: $0.01044**
**Monthly (2M calls): $20,880**

**Option 2: Standard API (With Prompt Caching)**

_GPT-4.1 (with caching):_

- First call: $0.0094
- Subsequent: (1,500 Ã— $2.00 + 800 Ã— $0.50 + 600 Ã— $8.00) / 1M = $0.0082
- Average: ~$0.0083

_GPT-4.1-mini (with caching):_

- First call: $0.00104
- Subsequent: (1,500 Ã— $0.40 + 300 Ã— $0.10 + 200 Ã— $1.60) / 1M = $0.00095
- Average: ~$0.00096

**Per call: ~$0.00926**
**Monthly (2M calls): ~$18,520**
**Savings: 11% vs no caching**

**Option 3: Batch API (Recommended for This Use Case)**

_GPT-4.1 (Batch):_

- Input: (2,300 tokens Ã— $1.00) / 1M = $0.0023
- Output: (600 tokens Ã— $4.00) / 1M = $0.0024
- Subtotal: $0.0047

_GPT-4.1-mini (Batch):_

- Input: (1,800 tokens Ã— $0.20) / 1M = $0.00036
- Output: (200 tokens Ã— $0.80) / 1M = $0.00016
- Subtotal: $0.00052

**Per call: $0.00522**
**Monthly (2M calls): $10,440**
**Savings: 50% vs Standard API**

**Why Batch API is Ideal for This Scenario:**

- âœ… Processing can be delayed 1-4 hours (meets "near real-time" requirement)
- âœ… Processes calls in micro-batches (1000 calls each)
- âœ… 50% cost reduction is significant at scale
- âœ… No impact on user experience (queries hit pre-processed data)
- âœ… Leverages both GPT-4.1 and GPT-4.1-mini efficiently

**Option 4: Provisioned Throughput Units (PTU)**

PTU considerations for 2M calls/month with hybrid model usage:

- Total processing needed: ~1,540 calls/hour sustained (accounting for both model calls)
- With burst processing (4-hour windows): ~4,000 calls/hour
- Estimated PTU requirement: 25-35 PTUs (accounting for both GPT-4.1 and mini workloads)

**PTU Cost Analysis:**

- Monthly Reservation: 30 PTUs Ã— $286 = $8,580/month
- Yearly Commitment: 30 PTUs Ã— $286 Ã— 12 = $102,960/year ($8,580/month)

**PTU Breakeven Analysis:**

- Batch API cost @ 2M calls: $10,440/month
- PTU cost: $8,580/month
- **PTU becomes cheaper at ~1.65M calls/month**

**When PTU Makes Sense:**

- âœ… **For workloads exceeding 1.65M calls/month** (immediate ROI)
- âœ… **For predictable, high-volume workloads** (your 2M calls/month qualifies)
- âœ… **When you need guaranteed throughput** (no rate limiting during peak processing windows)
- âœ… **For cost predictability** (fixed monthly cost vs variable token costs)

**PTU Recommendation for This Use Case:**

- **Year 1 (400K calls/month):** Use Batch API (~$2,088/month)
- **Scale-up (1M calls/month):** Continue with Batch API (~$5,220/month)
- **Steady State (2M+ calls/month):** Switch to PTU Monthly Reservation (~$8,580/month for unlimited processing)

### Recommended LLM Cost Strategy

**Hybrid Model + Batch API Approach (Recommended):**

1. **Primary Processing (GPT-4.1 Batch):** Complex entity extraction ($9,400/month @ 2M calls)
2. **Secondary Processing (GPT-4.1-mini Batch):** Sentiment & categorization ($1,040/month @ 2M calls)
3. **Fabric Data Agent Queries:** Separate budget - NOT counted in these costs

**Total Entity Extraction LLM Costs:**

- **400K calls/month (Initial):** ~$2,088/month (Batch API)
- **2M calls/month (Standard State - Batch API):** ~$10,440/month
- **2M calls/month (Optimized - PTU):** ~$8,580/month (16% savings + guaranteed throughput)

### Infrastructure Costs (Azure)

- **Microsoft Fabric:** ~$5,000-10,000/month
  - Spark processing (entity extraction orchestration)
  - Data warehouse (aggregated tables)
  - OneLake storage (hot + cold tiers)
- **Azure OpenAI (Entity Extraction Only):**
  - Batch API: $10,440/month @ 2M calls
  - PTU: $8,580/month @ 2M calls (cheaper at scale)
- **Azure OpenAI (Fabric Data Agent Queries):** ~$500-1,500/month (separate budget)
  - Natural language queries via Fabric Data Agent
  - NL2SQL + Vector search operations
  - Estimated 10K-30K queries/month
- **Azure AI Search:** ~$500-1,000/month (vector indexing)
- **Azure Redis Cache:** ~$200-500/month (query caching)
- **Azure Monitor + App Insights:** ~$500/month
- **Storage (Blob + Archive):** ~$1,000/month

**Total Monthly Cost:**

- **Standard Deployment (Batch API):** $28,140-34,940/month for 2M calls
- **Optimized Deployment (PTU for extraction):** $26,280-32,580/month for 2M calls
- **Per-call cost (fully loaded):** $0.013-0.017

### Cost Optimization Strategies

1. **Leverage Batch API (Primary Strategy)**

   - 50% immediate cost reduction on LLM processing
   - Fits perfectly with 1-4 hour processing latency requirement
   - Enables hybrid GPT-4.1 + GPT-4.1-mini approach

2. **Implement Prompt Caching**

   - Cache system prompts and entity reference lists
   - 50-75% reduction on cached tokens
   - Critical for minimizing repetitive prompt costs across 2M calls

3. **Strategic Model Selection (GPT-4.1 + mini hybrid)**

   - **GPT-4.1:** Complex extractions requiring reasoning (competitors, promotions, cancellation root cause)
   - **GPT-4.1-mini:** Pattern matching tasks (sentiment, categorization, scoring)
   - Hybrid approach saves ~10% vs GPT-4.1-only ($1,040/month @ 2M calls)

4. **Pre-filter Calls**

   - Skip entity extraction for calls <30 seconds (disconnects, wrong numbers)
   - Reduce processing volume by 10-15%
   - Potential savings: $1,000-1,500/month

5. **Optimize Batch Sizes**

   - Process in optimal micro-batches (1000 calls)
   - Maximize throughput while minimizing retries
   - Reduce token waste from failed/partial batches

6. **PTU for Predictable Costs at Scale**

   - Switch to PTU at 1.65M+ calls/month for immediate ROI
   - Lock in pricing with monthly reservation (no long-term commitment needed)
   - Eliminate variable cost risk and rate limiting
   - Guaranteed throughput for 4-hour batch processing windows

7. **Separate Fabric Data Agent Budget**
   - Don't count user query costs against extraction pipeline
   - Query costs are variable based on user activity, not call volume
   - Cache common executive queries aggressively (Redis)

This architecture provides enterprise-scale processing, maintains low query latency, and keeps costs predictable while delivering the natural language interface your executives need.
